{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import re\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1893\n",
      "1892\n"
     ]
    }
   ],
   "source": [
    "#读取停用词\n",
    "stop_words = []\n",
    "with open(\"data/project_data/stop_words.txt\", \"r\", encoding=\"utf-8\") as f_reader:\n",
    "    for line in f_reader:\n",
    "        # \\r回车符\n",
    "        line = line.replace(\"\\r\", \"\").replace(\"\\n\", \"\").strip()\n",
    "        stop_words.append(line)\n",
    "print(len(stop_words))\n",
    "stop_words = set(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\bruce\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.707 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#文本预处理\n",
    "sentecnces = []\n",
    "# 找出全部中文\n",
    "rules = u\"[\\u4e00-\\u9fa5]+\"\n",
    "pattern = re.compile(rules)\n",
    "f_writer = open(\"data/example_data/分词后的天龙八部.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "with open(\"data/example_data/天龙八部.txt\", \"r\" , encoding=\"utf-8\") as f_reader:\n",
    "    for line in f_reader:\n",
    "        line = line.replace(\"\\r\", \"\").replace(\"\\n\", \"\").strip()\n",
    "        if line == \"\" or line is None:\n",
    "            continue\n",
    "        line = \" \".join(jieba.cut(line))\n",
    "        seg_list = pattern.findall(line)\n",
    "        word_list = []\n",
    "        for word in seg_list:\n",
    "            if word not in stop_words:\n",
    "                word_list.append(word)\n",
    "        if len(word_list) > 0:\n",
    "            sentecnces.append(word_list)\n",
    "            line = \" \".join(word_list)\n",
    "            f_writer.write(line + \"\\n\")\n",
    "            f_writer.flush()\n",
    "f_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['书名', '天龙八部'], ['作者', '金庸'], ['本文', '早安', '电子书', '网友', '分享', '版权', '原作者'], ['用于', '商业行为', '后果自负'], ['早安', '电子书'], ['金庸', '作品集', '三联', '版', '序'], ['小学', '时', '爱读', '课外书', '低年级', '时看', '儿童', '画报', '小朋友', '小学生', '内容', '小朋友', '文库', '似懂非懂', '阅读', '各种各样', '章回小说', '五六年', '级', '时', '看新', '文艺作品', '喜爱', '古典文学', '作品', '多于', '近代', '当代', '新文学', '个性', '使然', '朋友', '喜欢', '新文学', '不爱', '古典文学'], ['知识', '当代', '书报', '中', '寻求', '小学', '时代', '得益', '记忆', '最深', '爸爸', '哥哥', '购置', '邹韬奋', '所撰', '萍踪', '寄语', '萍踪', '忆语', '世界各地', '旅行', '记', '主编', '生活', '周报', '新', '旧', '童年时代', '深受', '邹先生', '生活', '书店', '之惠', '生活', '书店', '三联书店', '组成部分', '十多年', '前', '香港三联书店', '签', '合同', '中国', '大陆', '地区', '出版', '小说', '因事', '未果', '重', '行', '筹划', '三联书店', '独家', '出版', '中国', '大陆', '地区', '简体字', '感到', '欣慰', '回忆', '昔日', '心中', '充满', '温馨', '之意'], ['撰写', '这套', '总数', '三十六', '册', '作品集', '是从', '一九五五年', '七二年', '约', '十三', '四年', '包括', '十二部', '长篇小说', '两篇', '中篇小说', '一篇', '短篇小说', '一篇', '历史', '人物', '评传', '若干篇', '历史', '考据', '文字', '出版', '过程', '奇怪', '香港', '台湾', '海外', '地区', '中国', '大陆', '先出', '各种各样', '翻版', '盗印', '出版', '校订', '授权', '正', '版本', '中国', '大陆', '三联', '版', '出版', '天津', '百花文艺出版社', '一家', '授权', '出版', '书剑', '恩仇录', '校印', '依足', '合同', '支付', '版税', '依足', '法例', '缴付', '所得税', '余数', '捐给', '几家', '文化', '机构', '支助', '围棋', '活动', '这是', '愉快', '经验', '未经', '授权'], ['不付', '版税', '版本', '粗制滥造', '错讹', '百出', '借用', '金庸', '之名', '撰写', '出版', '武侠小说', '写', '不敢掠美', '充满', '无聊', '打斗', '色情', '描写', '之作', '令人', '不快', '出版社', '翻印', '香港', '台湾', '作家', '作品', '而用', '笔名', '出版发行', '收到', '无数', '读者', '来信', '揭露', '大表', '愤慨', '三联', '版', '发行', '制止', '种种', '讲', '道义', '侠义', '小说', '主旨', '讲', '是非', '讲', '道义', '太', '过份']]\n"
     ]
    }
   ],
   "source": [
    "print(sentecnces[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#模型训练\n",
    "model = word2vec.Word2Vec(sentecnces, iter=50, size=100, window=3, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "白世镜 0.46209681034088135\n",
      "宋长老 0.4431273341178894\n",
      "徐长老 0.40213707089424133\n",
      "玄慈 0.3699125647544861\n",
      "乔大爷 0.3584541380405426\n",
      "鲍千灵 0.3493095338344574\n",
      "谭公 0.3465454578399658\n",
      "努儿海 0.3400297462940216\n",
      "马夫人 0.33992263674736023\n",
      "陈长老 0.3371778130531311\n"
     ]
    }
   ],
   "source": [
    "#选出10个与乔峰最相近的10个词\n",
    "for e in model.most_similar(positive=[\"乔峰\"], topn=10):\n",
    "    print(e[0], e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载预料\n",
    "sentences2 = word2vec.Text8Corpus(\"data/example_data/分词后的天龙八部.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.word2vec.Text8Corpus object at 0x000002203F199DA0>\n"
     ]
    }
   ],
   "source": [
    "print(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "model = word2vec.Word2Vec(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿紫道 0.996263861656189\n",
      "姊夫 0.9961894750595093\n",
      "冷冷的 0.9957616329193115\n",
      "找 0.995625376701355\n",
      "两位 0.9950875639915466\n",
      "赵钱孙 0.9950235486030579\n",
      "全冠清 0.9950124025344849\n",
      "乔帮主 0.9949069023132324\n",
      "姊姊 0.9948595762252808\n",
      "叹 0.9947936534881592\n"
     ]
    }
   ],
   "source": [
    "#选出10个与乔峰最相近的10个词\n",
    "for e in model.most_similar(positive=[\"乔峰\"], topn=10):\n",
    "    print(e[0], e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保存模型\n",
    "model.save(\"data/example_data/天龙八部.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载模型\n",
    "model2 = word2vec.Word2Vec.load(\"data/example_data/天龙八部.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿紫道 0.996263861656189\n",
      "姊夫 0.9961894750595093\n",
      "冷冷的 0.9957616329193115\n",
      "找 0.995625376701355\n",
      "两位 0.9950875639915466\n",
      "赵钱孙 0.9950235486030579\n",
      "全冠清 0.9950124025344849\n",
      "乔帮主 0.9949069023132324\n",
      "姊姊 0.9948595762252808\n",
      "叹 0.9947936534881592\n"
     ]
    }
   ],
   "source": [
    "#选出10个与乔峰最相近的10个词\n",
    "for e in model2.most_similar(positive=[\"乔峰\"], topn=10):\n",
    "    print(e[0], e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983976449658\n"
     ]
    }
   ],
   "source": [
    "#计算两个词语的相似度\n",
    "sim_value = model.similarity('乔峰','萧峰')\n",
    "print(sim_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988961361533\n"
     ]
    }
   ],
   "source": [
    "#计算两个集合的相似度\n",
    "list1 = ['乔峰','萧远山']\n",
    "list2= ['慕容复','慕容博']\n",
    "sim_value = model.n_similarity(list1, list2)\n",
    "print(sim_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丁春秋\n"
     ]
    }
   ],
   "source": [
    "#选出集合中不同类型的词语\n",
    "list3 = ['段誉','阿紫','王语嫣','丁春秋']\n",
    "print(model.doesnt_match(list3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#查看词向量值\n",
    "print(type(model['乔峰']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(model['乔峰']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0956201   0.83770102 -0.50264329  0.17705031 -0.03397365  0.53726691\n",
      " -0.94604319 -0.62564951 -0.16479155 -0.56092721 -0.05749961  0.19491424\n",
      "  0.23317778  0.69680882 -0.01325463  0.49103716 -0.2274354  -0.27408433\n",
      "  0.30029318  0.30257019  0.38569745 -0.24391353 -0.20851924 -1.03797174\n",
      "  0.1151455  -0.12836897 -0.25457156 -0.21057677 -0.59543329 -0.41599837\n",
      " -0.13542509  0.23070075 -0.0045849  -0.12233413  0.35966769  0.30875343\n",
      " -0.55712724 -0.05722067 -0.20944791  0.12286058 -0.49387416  0.26767832\n",
      " -0.03382351 -0.09347658  0.6634863   0.25116423 -0.17000762 -0.41160905\n",
      "  0.26862589 -0.48492855 -0.2278533   0.45218593 -0.15033394  0.17578831\n",
      " -0.58941668 -0.0460459   0.04037135  0.27327055 -0.22823675  0.2203647\n",
      "  0.05365429 -0.04600301 -0.7688188   0.13671628 -0.53027683 -0.1469509\n",
      "  1.03760362  0.12982909 -0.22781004  0.54549789  0.05604199 -0.42564315\n",
      " -0.06961453 -0.16930862 -0.73733568 -0.40141526  0.83430684 -0.35497716\n",
      "  0.45108098  0.59830898  0.56303334  0.40351576  0.08104084 -0.05698548\n",
      " -0.54859221  0.25344476 -0.3362723  -0.22261383 -0.2233018   0.040442\n",
      "  0.42754599 -1.2365644   0.56711614  0.03170419 -0.08998632  0.26160204\n",
      "  0.18751431  0.04812396 -0.26835883  0.34943965]\n"
     ]
    }
   ],
   "source": [
    "print(model['乔峰'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
